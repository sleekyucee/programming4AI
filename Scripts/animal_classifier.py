# -*- coding: utf-8 -*-
"""Programming_and_Maths_INM702_CourseWork_TaskTwo_Amua_U

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1U9R2IkzYZBR43Sr25kK3Nbrv-6zGezX5

# **Import Necessary Dependencies and Libraries**
"""

!pip install opendatasets

#PyTorch libraries
import torch
import torch.nn as nn
from torch.utils.data import Dataset
import torch.optim as optim
from torch.optim import Adam, SGD
import torch.nn.functional as F
import torchvision.models as models
from torchvision.models import alexnet

#Data handling libraries
import opendatasets as od
import pandas as pd
import numpy as np
import torchvision.transforms as transforms
from torchvision.datasets import ImageFolder
from torch.utils.data import DataLoader
from tqdm import tqdm
import copy

#Scikit-learn libraries
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.model_selection import cross_val_score, StratifiedKFold, ParameterGrid

#System and utilities
import sys
sys.path.append("path")
import warnings
warnings.filterwarnings("ignore")
import pickle

#File and folder manipulation
import os
import cv2
import shutil
import random

#Data visualization
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
from IPython.display import display
from PIL import Image
import seaborn as sns
import plotly.express as px

#Time tracking
import time

"""# **Data Importing & Exploration**

## **Load Data**
"""

#download dataset
od.download("https://www.kaggle.com/datasets/borhanitrash/animal-image-classification-dataset")

#check if GPU is available
if torch.cuda.is_available():
    device = torch.device('cuda')
else:
    device = torch.device('cpu')
print("Device:",device)

#define data directory and subdirectories
data_dir = "./animal-image-classification-dataset"
animals_dir = os.path.join(data_dir, "Animals")
cats_dir = os.path.join(animals_dir, "cats")
snakes_dir = os.path.join(animals_dir, "snakes")
dogs_dir = os.path.join(animals_dir, "dogs")

#define train, validation, and test directory paths
train_dir = os.path.join(data_dir, "train")
val_dir = os.path.join(data_dir, "val")
test_dir = os.path.join(data_dir, "test")

#create sub directories for each animal type within train_dir, val_dir, and test_dir
for animal_type in ["cats", "snakes", "dogs"]:
    os.makedirs(os.path.join(train_dir, animal_type), exist_ok=True)
    os.makedirs(os.path.join(val_dir, animal_type), exist_ok=True)
    os.makedirs(os.path.join(test_dir, animal_type), exist_ok=True)

"""## **Explore Data**"""

#get the number of samples for each class
num_cats = len(os.listdir(cats_dir))
num_snakes = len(os.listdir(snakes_dir))
num_dogs = len(os.listdir(dogs_dir))

#display number of samples in each class
print(f"Number of samples in cats directory: {num_cats}")
print(f"\nNumber of samples in snakes directory: {num_snakes}")
print(f"\nNumber of samples in dogs directory: {num_dogs}")

#display total number of samples
total_samples = num_cats + num_snakes + num_dogs
print(f"\nTotal number of samples: {total_samples}")

#bar plot to visualize number of samples
class_labels = ["cats", "dogs", "snakes"]
class_counts = [num_cats, num_dogs, num_snakes]
colors = ["#1f77b4", "#ff7f0e", "#2ca02c"]
plt.figure(figsize=(10, 6))
plt.bar(class_labels, class_counts, color=colors)
plt.xlabel("Class")
plt.ylabel("Number of Samples")
plt.show()

#display sample images of the classes of animal
sample_cat = os.path.join(cats_dir, os.listdir(cats_dir)[0])
sample_dog = os.path.join(dogs_dir, os.listdir(dogs_dir)[0])
sample_snake = os.path.join(snakes_dir, os.listdir(snakes_dir)[0])

#open and display the immages
fig, axs = plt.subplots(1, 3, figsize=(15, 5))
axs[0].imshow(Image.open(sample_cat))
axs[0].set_title("Cat")
axs[0].axis("off")
axs[1].imshow(Image.open(sample_dog))
axs[1].set_title("Dog")
axs[1].axis("off")
axs[2].imshow(Image.open(sample_snake))
axs[2].set_title("Snake")
axs[2].axis("off")
plt.show()

#check random image shape
img1 = cv2.imread(sample_cat)
img2 = cv2.imread(sample_dog)
img3 = cv2.imread(sample_snake)
display(img1.shape, img2.shape, img3.shape)

"""## **Split Data**"""

#define split ratios
train_ratio = 0.7
val_ratio = 0.1
test_ratio = 0.2

#define a function to split data into train_dir, val_dir, test_dir
def split_data(src_dir, train_dir, val_dir, test_dir, train_ratio, val_ratio, test_ratio):
    files = os.listdir(src_dir)
    random.shuffle(files)
    total_files = len(files)

    train_split = int(total_files * train_ratio)
    val_split = int(total_files * val_ratio)
    test_split = int(total_files * test_ratio)

    train_files = files[:train_split]
    val_files = files[train_split:(train_split + val_split)]
    test_files = files[(train_split + val_split):]

    for file in train_files:
        src_path = os.path.join(src_dir, file)
        dst_path = os.path.join(train_dir, file)
        if os.path.isfile(src_path):
            shutil.copy(src_path, dst_path)

    for file in val_files:
        src_path = os.path.join(src_dir, file)
        dst_path = os.path.join(val_dir, file)
        if os.path.isfile(src_path):
            shutil.copy(src_path, dst_path)

    for file in test_files:
        src_path = os.path.join(src_dir, file)
        dst_path = os.path.join(test_dir, file)
        if os.path.isfile(src_path):
            shutil.copy(src_path, dst_path)

#split data
split_data(cats_dir,
           os.path.join(train_dir, "cats"),
           os.path.join(val_dir, "cats"),
           os.path.join(test_dir, "cats"),
           train_ratio,
           val_ratio,
           test_ratio
)

split_data(dogs_dir,
           os.path.join(train_dir, "dogs"),
           os.path.join(val_dir, "dogs"),
           os.path.join(test_dir, "dogs"),
           train_ratio,
           val_ratio,
           test_ratio
)

split_data(snakes_dir,
           os.path.join(train_dir, "snakes"),
           os.path.join(val_dir, "snakes"),
           os.path.join(test_dir, "snakes"),
           train_ratio,
           val_ratio,
           test_ratio
)

#count samples in each class and directory after splitting
train_cats = len(os.listdir(os.path.join(train_dir, "cats")))
train_dogs = len(os.listdir(os.path.join(train_dir, "dogs")))
train_snakes = len(os.listdir(os.path.join(train_dir, "snakes")))

val_cats = len(os.listdir(os.path.join(val_dir, "cats")))
val_dogs = len(os.listdir(os.path.join(val_dir, "dogs")))
val_snakes = len(os.listdir(os.path.join(val_dir, "snakes")))

test_cats = len(os.listdir(os.path.join(test_dir, "cats")))
test_dogs = len(os.listdir(os.path.join(test_dir, "dogs")))
test_snakes = len(os.listdir(os.path.join(test_dir, "snakes")))

#total samples in each class
cats_total = train_cats + val_cats + test_cats
dogs_total = train_dogs + val_dogs + test_dogs
snakes_total = train_snakes + val_snakes + test_snakes

#total train, val, and test samples
train_total = train_cats + train_dogs + train_snakes
val_total = val_cats + val_dogs + val_snakes
test_total = test_cats + test_dogs + test_snakes

#total samples in entire dataset
total_samples = cats_total + dogs_total + snakes_total

#display counts
print(f"Cats - \nTrain: {train_cats}, \nVal: {val_cats}, \nTest: {test_cats}, \nTotal: {cats_total}")
print(f"\nDogs - \nTrain: {train_dogs}, \nVal: {val_dogs}, \nTest: {test_dogs}, \nTotal: {dogs_total}")
print(f"\nSnakes - \nTrain: {train_snakes}, \nVal: {val_snakes}, \nTest: {test_snakes}, \nTotal: {snakes_total}")
print(f"\nTotal Train: {train_total}, \nTotal Val: {val_total}, \nTotal Test: {test_total}, \nTotal Data: {total_samples}")

"""## **Create DataFrames**"""

#initialize dict to store df of split data(train, val, test)
data_dict = {"train": None, "val": None, "test": None}

#loop through each split
for split, split_dir in [("train", train_dir), ("val", val_dir), ("test", test_dir)]:
    #initialize empty list to store data
    data = []

    for animal_type in ["cats", "dogs", "snakes"]:
        animal_dir = os.path.join(split_dir, animal_type)
        for image_name in os.listdir(animal_dir):
            data.append(
                {
                    "Label": animal_type,
                    "Image_Name": image_name,
                }
            )

    #create df from data
    data_dict[split] = pd.DataFrame(data)

#retrieve dataframes
train_df = data_dict["train"]
val_df = data_dict["val"]
test_df = data_dict["test"]

#display 5 random rows of train df, val df, and test df
display(train_df.sample(5), val_df.sample(5), test_df.sample(5))

"""## **Labels to Numeric**"""

#retrieve class names from labels and map classes to numbers
for df in [train_df, val_df, test_df]:
    class_names = df["Label"].unique()
    class_to_num = {class_name: i for i, class_name in enumerate(class_names)}
    df["Label"] = df["Label"].map(class_to_num)

#view changes
display(train_df.sample(5), val_df.sample(5), test_df.sample(5))

#save train, val, and test data as csv files
train_df.to_csv("train.csv", index=False)
val_df.to_csv("val.csv", index=False)
test_df.to_csv("test.csv", index=False)

"""## **Data Transformations**

**Transforms 1**
"""

#define data transformations for train set
train_transforms = transforms.Compose(
    [
        transforms.RandomRotation(20),
        transforms.Resize((356, 356)),
        transforms.RandomHorizontalFlip(),
        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),
        transforms.RandomCrop((299, 299)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),
    ]
)

#define data transformations for val and test data
val_test_transforms = transforms.Compose(
    [
        transforms.Resize((356, 356)),
        transforms.CenterCrop((299, 299)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),
    ]
)

"""**Transforms 2**"""

#define data transformations for train set
train_transforms2 = transforms.Compose(
    [
        transforms.RandomRotation(20),
        transforms.RandomHorizontalFlip(),
        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),
        transforms.RandomCrop((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
    ]
)

#define data transformations for val and test data
val_test_transforms2 = transforms.Compose(
    [
        transforms.CenterCrop((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
    ]
)

"""## **Create Dataset**"""

class CatsDogsAndSnakes(Dataset):
    def __init__(self, csv_file, root_dir, transform=None):
        self.data = pd.read_csv(csv_file)
        self.root_dir = root_dir
        self.transform = transform
        self.class_names = ['cats', 'dogs', 'snakes']

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        label_index = self.data.iloc[idx, 0]
        animal_type = self.class_names[label_index]
        img_name = os.path.join(self.root_dir,
                                animal_type,
                                self.data.iloc[idx, 1])
        image = Image.open(img_name)
        label = self.data.iloc[idx, 0]

        if self.transform is not None:
            image = self.transform(image)

        return image, label

"""**Dataset 1**"""

#train dataset
train_dataset = CatsDogsAndSnakes(csv_file="train.csv", root_dir=train_dir, transform=train_transforms)

#val dataset
val_dataset = CatsDogsAndSnakes(csv_file="val.csv", root_dir=val_dir, transform=val_test_transforms)

#test dataset
test_dataset = CatsDogsAndSnakes(csv_file="test.csv", root_dir=test_dir, transform=val_test_transforms)

"""**Dataset 2**"""

#train dataset
train_dataset2 = CatsDogsAndSnakes(csv_file="train.csv", root_dir=train_dir, transform=train_transforms2)

#val dataset
val_dataset2 = CatsDogsAndSnakes(csv_file="val.csv", root_dir=val_dir, transform=val_test_transforms2)

#test dataset
test_dataset2 = CatsDogsAndSnakes(csv_file="test.csv", root_dir=test_dir, transform=val_test_transforms2)

#check shape of first samples
assert train_dataset[0][0].shape == val_dataset[0][0].shape == test_dataset[0][0].shape
assert train_dataset2[0][0].shape == val_dataset2[0][0].shape == test_dataset2[0][0].shape

#display shapes
print(f"Train: {train_dataset[0][0].shape}")
print(f"Val: {val_dataset[0][0].shape}")
print(f"Test: {test_dataset[0][0].shape}")

#display shapes
print(f"Train: {train_dataset2[0][0].shape}")
print(f"Val: {val_dataset2[0][0].shape}")
print(f"Test: {test_dataset2[0][0].shape}")

"""## **Create DataLoaders**"""

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
batch_size = 32
shuffleT = True
shuffleF = False

"""**DataLoader 1**"""

#train dataloader
train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=shuffleT)

#val dataloader
val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=shuffleF)

#test dataloader
test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=shuffleF)

"""**DataLoader 2**"""

#train dataloader
train_loader2 = DataLoader(train_dataset2, batch_size=batch_size, shuffle=shuffleT)

#val dataloader
val_loader2 = DataLoader(val_dataset2, batch_size=batch_size, shuffle=shuffleF)

#test dataloader
test_loader2 = DataLoader(test_dataset2, batch_size=batch_size, shuffle=shuffleF)

"""# **Models Development**

## **Model Summary Class**
"""

class ModelSummary:
    def __init__(self, model):
        self.model = model

    def __str__(self):
        model_summary = str(self.model) + "\n\n"
        total_trainable_params = 0
        total_frozen_params = 0

        for name, parameter in self.model.named_parameters():
            if parameter.requires_grad:
                total_trainable_params += parameter.numel()
                status = "Trainable"
            else:
                total_frozen_params += parameter.numel()
                status = "Frozen"

            model_summary += f"Layer: {name}, Parameters: {parameter.numel()}, Status: {status}\n"

        model_summary += f"Total Trainable Parameters: {total_trainable_params}\n"
        model_summary += f"Total Frozen Parameters: {total_frozen_params}"

        return model_summary

"""## **Model Train Class**"""

class Trainer:
    def __init__(self, model, train_loader, val_loader, criterion=None, optimizer=None, device="cuda", num_epochs=100, model_name=None, verbose=False):
        self.model = model.to(device)
        self.train_loader = train_loader
        self.val_loader = val_loader
        self.criterion = criterion.to(device)
        self.optimizer = optimizer
        self.device = device
        self.num_epochs = num_epochs
        self.model_name = model_name
        self.verbose = verbose
        self.train_acc_history = []
        self.val_acc_history = []
        self.train_loss_history = []
        self.val_loss_history = []

    def train(self, verbose=False):
        start_time = time.time()

        for epoch in range(self.num_epochs):
            total_correct = 0
            total_samples = 0
            total_loss = 0.0

            if self.verbose:
                train_data_loader = tqdm(self.train_loader, position=0)
            else:
                train_data_loader = self.train_loader

            for batch_idx, (inputs, labels) in enumerate(train_data_loader):
                inputs, labels = inputs.to(self.device), labels.to(self.device)
                self.optimizer.zero_grad()
                outputs = self.model(inputs)
                loss = self.criterion(outputs, labels)
                loss.backward()
                self.optimizer.step()

                _, predicted = outputs.max(1)
                total_samples += labels.size(0)
                total_correct += (predicted == labels).sum().item()
                total_loss += loss.item()

                train_accuracy = total_correct / total_samples
                train_loss = total_loss / total_samples
                self.train_acc_history.append(train_accuracy)
                self.train_loss_history.append(train_loss)

                if self.verbose:
                    description = f'Epoch [{epoch + 1}/{self.num_epochs}], Batch [{batch_idx + 1}/{len(train_data_loader)}], Training Loss: {train_loss:.4f}, Training Accuracy: {train_accuracy * 100:.2f}%'
                    train_data_loader.set_description(description, refresh=True)

            if self.verbose:
                train_data_loader.close()

            total_correct_val = 0
            total_samples_val = 0
            total_loss_val = 0.0

            # Validation phase
            self.model.eval()

            with torch.no_grad():
                if self.verbose:
                    val_data_loader = tqdm(self.val_loader, position=0)
                else:
                    val_data_loader = self.val_loader

                for batch_idx, (inputs, labels) in enumerate(val_data_loader):
                    inputs, labels = inputs.to(self.device), labels.to(self.device)
                    outputs = self.model(inputs)
                    loss = self.criterion(outputs, labels)
                    total_loss_val += loss.item()

                    _, predicted = outputs.max(1)
                    total_samples_val += labels.size(0)
                    total_correct_val += (predicted == labels).sum().item()

                    val_accuracy = total_correct_val / total_samples_val
                    val_loss = total_loss_val / total_samples_val
                    self.val_acc_history.append(val_accuracy)
                    self.val_loss_history.append(val_loss)

                    if self.verbose:
                        description = f'Epoch [{epoch + 1}/{self.num_epochs}], Batch [{batch_idx + 1}/{len(val_data_loader)}], Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy * 100:.2f}%'
                        val_data_loader.set_description(description, refresh=True)

                if self.verbose:
                    val_data_loader.close()

        print("\nTraining completed!")
        end_time = time.time()
        training_time = end_time - start_time
        print(f"Training took {self.format_time(training_time)}\n")

        # Save model
        model_save_path = f'{self.model_name}.pth'
        self.save_model(model_save_path)
        print(f"Model saved at {model_save_path}")

    def save_model(self, save_path):
        torch.save(self.model.state_dict(), save_path)

    def format_time(self, seconds):
        minutes, seconds = divmod(seconds, 60)
        hours, minutes = divmod(minutes, 60)
        return f"{int(hours)} hours, {int(minutes)} minutes, {int(seconds)} seconds"

"""## **Model Training Curve Class**"""

class TrainCurvePlotter:
    def __init__(self, train_history_file):
        self.train_history_file = train_history_file
        self.train_loss = None
        self.train_acc = None
        self.val_loss = None
        self.val_acc = None
        self.num_epochs = None

    def load_training_history(self):
        with open(self.train_history_file, 'rb') as file:
            history = pickle.load(file)
            self.train_loss = history['train_loss_history']
            self.train_acc = history['train_acc_history']
            self.val_loss = history['val_loss_history']
            self.val_acc = history['val_acc_history']
            train_batches_per_epoch = len(self.train_loss) // len(self.val_loss)

            self.num_epochs = len(self.val_loss)

    def plot(self):
        #load the training history data
        self.load_training_history()

        train_batches_per_epoch = len(self.train_loss) // len(self.val_loss)

        #calculate mean loss and accuracy values per epoch
        train_losses = [np.mean(self.train_loss[i:i+train_batches_per_epoch]) for i in range(0, len(self.train_loss), train_batches_per_epoch)]
        train_accuracies = [np.mean(self.train_acc[i:i+train_batches_per_epoch]) for i in range(0, len(self.train_acc), train_batches_per_epoch)]
        val_losses = self.val_loss
        val_accuracies = self.val_acc

        #align lengths
        min_len = min(len(train_losses), len(val_losses))
        train_losses = train_losses[:min_len]
        train_accuracies = train_accuracies[:min_len]
        val_losses = val_losses[:min_len]
        val_accuracies = val_accuracies[:min_len]

        #create an epoch range based on the number of epochs
        epochs = range(1, self.num_epochs + 1)

        #check len train and val loss are equal
        assert len(train_losses) == len(val_losses)

        #plot training loss and accuracy
        plt.figure(figsize=(12, 4))
        plt.subplot(1, 2, 1)
        plt.plot(epochs, train_losses, label='Training Loss')
        plt.plot(epochs, val_losses, label='Validation Loss')
        plt.title('Training and Validation Loss')
        plt.xlabel('Epochs')
        plt.legend()

        plt.subplot(1, 2, 2)
        plt.plot(epochs, train_accuracies, label='Training Accuracy')
        plt.plot(epochs, val_accuracies, label='Validation Accuracy')
        plt.title('Training and Validation Accuracy')
        plt.xlabel('Epochs')
        plt.legend()

        plt.tight_layout()
        plt.show()

"""## **Model Evaluator Class**"""

class ModelEvaluator:
    def __init__(self, model, dataloader, device):
        self.model = model
        self.dataloader = dataloader
        self.device = device

    def evaluate(self):
        self.model.eval()

        total_correct = 0
        total_samples = 0

        for inputs, labels in self.dataloader:
            inputs, labels = inputs.to(self.device), labels.to(self.device)
            outputs = self.model(inputs)

            _, predicted = outputs.max(1)
            total_samples += labels.size(0)
            total_correct += (predicted == labels).sum().item()

        accuracy = total_correct / total_samples

        return accuracy

"""## **Model Predictor Class**"""

class ModelPredictor:
    def __init__(self, model, dataloader, device):
        self.model = model
        self.dataloader = dataloader
        self.device = device

    def predict(self):
        predictions = []
        true_labels = []

        with torch.no_grad():
            for inputs, labels in self.dataloader:
                inputs, labels = inputs.to(self.device), labels.to(self.device)
                outputs = self.model(inputs)
                predicted = outputs.argmax(dim=1)

                predictions.extend(predicted.cpu().numpy())
                true_labels.extend(labels.cpu().numpy())

        predictions = np.array(predictions)
        true_labels = np.array(true_labels)

        return predictions, true_labels


    def plot_predictions(self):
        predictions, true_labels = self.predict()

        # Create a grouped bar chart
        classes = np.unique(true_labels)
        class_labels = [str(cls) for cls in classes]

        width = 0.35
        ind = np.arange(len(classes))

        true_counts = [0] * len(classes)
        predicted_counts = [0] * len(classes)

        for true, pred in zip(true_labels, predictions):
            true_counts[true] += 1
            predicted_counts[pred] += 1

        fig, ax = plt.subplots(figsize=(10, 6))
        p1 = ax.bar(ind - width / 2, true_counts, width, label='True Labels')
        p2 = ax.bar(ind + width / 2, predicted_counts, width, label='Predicted Labels')

        ax.set_xlabel('Classes')
        ax.set_ylabel('Counts')
        ax.set_title('True vs. Predicted Labels')
        ax.set_xticks(ind)
        ax.set_xticklabels(class_labels)
        ax.legend()

        #annotate the bars with counts
        for i in range(len(classes)):
            ax.annotate(str(true_counts[i]), (ind[i] - width / 2, true_counts[i] + 1), ha='center', color='blue')
            ax.annotate(str(predicted_counts[i]), (ind[i] + width / 2, predicted_counts[i] + 1), ha='center', color='orange')

        plt.show()

"""## **Model Performance Class**"""

class PerformanceMetrics:
    def __init__(self, true_labels, predicted_labels, class_names):
        self.true_labels = true_labels
        self.predicted_labels = predicted_labels
        self.class_names = class_names

    def calculate_accuracy(self):
        accuracy = accuracy_score(self.true_labels, self.predicted_labels)
        return accuracy * 100

    def calculate_confusion_matrix(self):
        return confusion_matrix(self.true_labels, self.predicted_labels)

    def calculate_specificity(self):
        conf_matrix = self.calculate_confusion_matrix()
        true_negatives = conf_matrix[0, 0]
        false_positives = conf_matrix[0, 1]
        specificity = true_negatives / (true_negatives + false_positives) * 100
        return specificity

    def calculate_sensitivity(self):
        conf_matrix = self.calculate_confusion_matrix()
        true_positives = conf_matrix[1, 1]
        false_negatives = conf_matrix[1, 0]
        sensitivity = true_positives / (true_positives + false_negatives) * 100
        return sensitivity

    def calculate_precision(self):
        conf_matrix = self.calculate_confusion_matrix()
        true_positives = conf_matrix[1, 1]
        false_positives = conf_matrix[0, 1]
        precision = true_positives / (true_positives + false_positives) * 100
        return precision

    def generate_classification_report(self):
        return classification_report(self.true_labels, self.predicted_labels, target_names=self.class_names)

    def plot_heatmap(self):
        conf_matrix = self.calculate_confusion_matrix()
        plt.figure(figsize=(8, 6))
        sns.heatmap(conf_matrix, annot=True, fmt="d", cmap="YlGnBu", xticklabels=self.class_names, yticklabels=self.class_names)
        plt.xlabel('Predicted')
        plt.ylabel('True')
        plt.title('Confusion Matrix Heatmap')
        plt.show()

"""## Model Comparison Class"""

class ModelComparison:
    def __init__(self, model_results):
        self.model_results = model_results

    def plot_metric(self, metric_name, plot_title):
        data = []
        for model, metrics in self.model_results.items():
            data.append({'Model': model, metric_name: metrics[metric_name]})

        df = pd.DataFrame(data)

        #find the model with the best score for the metric
        best_model = df[df[metric_name] == df[metric_name].max()]['Model'].values[0]
        print(f"Best model for {metric_name}: {best_model} ({df[metric_name].max()}%)")

        fig = px.bar(df, x='Model', y=metric_name, title=plot_title)
        fig.show()

    def plot_accuracy(self):
        self.plot_metric('Accuracy', 'Model Accuracy Comparison')

    def plot_specificity(self):
        self.plot_metric('Specificity', 'Model Specificity Comparison')

    def plot_sensitivity(self):
        self.plot_metric('Sensitivity', 'Model Sensitivity Comparison')

    def plot_precision(self):
        self.plot_metric('Precision', 'Model Precision Comparison')

"""## **Model One**

**Build Model**
"""

#model architecture
class AnimalClassifier(nn.Module):
    def __init__(self,
                 num_classes=3,
                 conv1_out_channels=32,
                 conv2_out_channels=64,
                 conv3_out_channels=128):
        super(AnimalClassifier, self).__init__()

        self.conv1 = nn.Conv2d(
            in_channels=3,  #input channels (RGB image)
            out_channels=conv1_out_channels,  #no of output channels
            kernel_size=3,  #size of convolution kernel
            stride=1,  #convolution stride
            padding=1  #padding applied to the input
        )
        self.conv2 = nn.Conv2d(
            in_channels=conv1_out_channels,
            out_channels=conv2_out_channels,
            kernel_size=3,
            stride=1,
            padding=1
        )
        self.conv3 = nn.Conv2d(
            in_channels=conv2_out_channels,
            out_channels=conv3_out_channels,
            kernel_size=3,
            stride=1,
            padding=1
        )
        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)  #max pooling layer
        self.fc1 = nn.Linear(conv3_out_channels * 37 * 37, 512)  #fully connected layer
        self.fc2 = nn.Linear(512, num_classes)  #output layer

    def forward(self, x):
        x = self.pool(F.relu(self.conv1(x)))
        x = self.pool(F.relu(self.conv2(x)))
        x = self.pool(F.relu(self.conv3(x)))
        x = x.view(x.size(0), -1)   #flatten the feature maps
        x = F.relu(self.fc1(x))
        x = self.fc2(x)
        return x

"""**Get Summary**"""

#model summary
model1 = AnimalClassifier()

#instantiate model summary class
model_summary = ModelSummary(model1)

#display model summary
print(model_summary)

"""**Train Model**"""

def set_seed(seed=42):
    #Sets the random seed for Python, NumPy, and PyTorch
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False

#set seed before training
set_seed(seed=36)

#train model one
#initialize model
model1 = AnimalClassifier()

#set parameters
optimizer = torch.optim.SGD
optimizer_params = {'lr': 0.0001}

#instantiate optimizer
optimizer_instance = optimizer(model1.parameters(), **optimizer_params)

#set epochs
num_epochs = 50

#instantiate trainer
trainer = Trainer(
    model=model1,
    train_loader=train_loader,
    val_loader=val_loader,
    criterion=nn.CrossEntropyLoss().to(device),
    optimizer=optimizer_instance,
    device=device,
    num_epochs=num_epochs,
    model_name='model1',
    verbose=True
)

#train model
trainer.train()

def save_training_history(history, file_path):
    """Saves the training history to a pickle file."""
    with open(file_path, 'wb') as file:
        pickle.dump(history, file)

#save training history for model 1
history1 = {
    'train_loss_history': trainer.train_loss_history,
    'val_loss_history': trainer.val_loss_history,
    'train_acc_history': trainer.train_acc_history,
    'val_acc_history': trainer.val_acc_history,
}
save_training_history(history1, 'training_history_model1.pkl')

"""**Plot Training Curves**"""

#instantiate TrainCurvePlotter with saved training history
plotter = TrainCurvePlotter('training_history_model1.pkl')

#load training history
plotter.load_training_history()

#plot training curves
plotter.plot()

"""**Make Predictions**"""

#instantiate ModelPredictor
predictor = ModelPredictor(model1, val_loader, device)

#predict the class labels of all the images val loader
predictions, true_labels = predictor.predict()

#display predictions
print(f"Model One- Predictions: \n{predictions}")

#print the accuracy of the model on the val dataset
accuracy = (predictions == true_labels).mean()
print(f"\nModel One - Validation Accuracy: {accuracy * 100:.2f}%")

"""### **Model One Tuning - Using Adam Optimizer**"""

#load pretrained weights
model1 = AnimalClassifier()
model1.load_state_dict(torch.load('model1.pth'))  #load the saved weights

#set parameters for Adam optimizer
optimizer = torch.optim.Adam
optimizer_params = {'lr': 0.0001}

#instantiate Adam optimizer
optimizer_instance = optimizer(model1.parameters(), **optimizer_params)

#instantiate trainer
trainer = Trainer(
    model=model1,
    train_loader=train_loader,
    val_loader=val_loader,
    criterion=nn.CrossEntropyLoss().to(device),
    optimizer=optimizer_instance,
    device=device,
    num_epochs=num_epochs,
    model_name='model1_tuned',
    verbose=True
)

#train model
trainer.train()

#save training history of tuned model 1
history1 = {
    'train_loss_history': trainer.train_loss_history,
    'val_loss_history': trainer.val_loss_history,
    'train_acc_history': trainer.train_acc_history,
    'val_acc_history': trainer.val_acc_history,
}
save_training_history(history1, 'training_history_model1_tuned.pkl')

"""**Plot Training Curves**"""

#instantiate TrainCurvePlotter with saved training history
plotter = TrainCurvePlotter('training_history_model1_tuned.pkl')

#load training history
plotter.load_training_history()

#plot training curves
plotter.plot()

"""**Make Predictions**"""

#instantiate ModelPredictor
predictor = ModelPredictor(model1, val_loader, device)

#predict the class labels of all the images val loader
predictions, true_labels = predictor.predict()

#display predictions
print(f"Model One- Predictions: \n{predictions}")

#print the accuracy of the model on the val dataset
accuracy = (predictions == true_labels).mean()
print(f"\nModel One - Validation Accuracy: {accuracy * 100:.2f}%")

#get a random sample from val loader
random_batch = random.choice(val_loader.dataset)

#extract image and label from random sample
image, label = random_batch

#add a batch dimension to image
image = image.unsqueeze(0).to(device)

#make predictions for random image
outputs = model1(image)

#get the predicted class label
predicted_class_label = outputs[0].argmax().item()

#get the class names for the predicted and true labels
predicted_class_name = class_labels[predicted_class_label]
true_class_name = class_labels[label]

#display results
print(f"Predicted class label: {predicted_class_label}")
print(f"Predicted class name: {predicted_class_name}")
print(f"True class label: {label}")
print(f"True class name: {true_class_name}")

#move image to CPU for plotting
image = image.squeeze(0).cpu()

#convert image tensor to numpy array
image = image.permute(1, 2, 0).numpy()  #rearrange dimensions for matplotlib (H, W, C)

#plot the image
plt.figure(figsize=(6, 6))
plt.imshow(image)
plt.title(f"Predicted: {predicted_class_name}\nTrue: {true_class_name}", fontsize=16)
plt.axis('off')
plt.show()

#plot predictions vs. true labels
predictor.plot_predictions()

"""## **Model Two** -

Using Transfer Learning From Alex Net Pretrained Model

**Build Model**
"""

class AlexNetPretrained(nn.Module):
    def __init__(self, num_classes=3):
        super(AlexNetPretrained, self).__init__()
        self.alexnet = alexnet(pretrained=True)
        #modify the classifier (last layer) for your number of classes
        self.alexnet.classifier[6] = nn.Linear(4096, num_classes)

    def forward(self, x):
        x = self.alexnet(x)
        return x

"""**Get Summary**"""

#model summary
model2 = AlexNetPretrained()

#instantiate model summary class
model_summary = ModelSummary(model2)

#display model summary
print(model_summary)

"""**Train Model**"""

#set seed before training
set_seed(seed=36)

#train model two
#initialize model
model2 = AlexNetPretrained()

#set parameters
optimizer = torch.optim.Adam
optimizer_params = {'lr': 0.0001}

#instantiate optimizer
optimizer_instance = optimizer(model2.parameters(), **optimizer_params)

#instantiate trainer
trainer = Trainer(
    model=model2,
    train_loader=train_loader2,
    val_loader=val_loader2,
    criterion=nn.CrossEntropyLoss().to(device),
    optimizer=optimizer_instance,
    device=device,
    num_epochs=num_epochs,
    model_name='model2',
    verbose=True
)

#train model
trainer.train()

#save training history for model 2
history2 = {
    'train_loss_history': trainer.train_loss_history,
    'val_loss_history': trainer.val_loss_history,
    'train_acc_history': trainer.train_acc_history,
    'val_acc_history': trainer.val_acc_history,
}
save_training_history(history2, 'training_history_model2.pkl')

"""**Plot Training Curves**"""

#instantiate TrainCurvePlotter with saved training history
plotter = TrainCurvePlotter('training_history_model2.pkl')

#load training history
plotter.load_training_history()

#plot training curves
plotter.plot()

"""**Make Predictions**"""

#instantiate ModelPredictor
predictor = ModelPredictor(model2, val_loader2, device)

#predict the class labels of all the images val loader
predictions, true_labels = predictor.predict()

#display predictions
print(f"Model Two- Predictions: \n{predictions}")

#print the accuracy of the model on the val dataset
accuracy = (predictions == true_labels).mean()
print(f"\nModel Two - Validation Accuracy: {accuracy * 100:.2f}%")

#get a random sample from val loader
random_batch = random.choice(val_loader2.dataset)

#extract image and label from random sample
image, label = random_batch

#add a batch dimension to image
image = image.unsqueeze(0).to(device)

#make predictions for random image
outputs = model2(image)

#get the predicted class label
predicted_class_label = outputs[0].argmax().item()

#get the class names for the predicted and true labels
predicted_class_name = class_labels[predicted_class_label]
true_class_name = class_labels[label]

#display results
print(f"Predicted class label: {predicted_class_label}")
print(f"Predicted class name: {predicted_class_name}")
print(f"True class label: {label}")
print(f"True class name: {true_class_name}")

#move image to CPU for plotting
image = image.squeeze(0).cpu()

#convert image tensor to numpy array
image = image.permute(1, 2, 0).numpy()  #rearrange dimensions for matplotlib (H, W, C)

#plot the image
plt.figure(figsize=(6, 6))
plt.imshow(image)
plt.title(f"Predicted: {predicted_class_name}\nTrue: {true_class_name}", fontsize=16)
plt.axis('off')
plt.show()

#plot predictions vs. true labels
predictor.plot_predictions()

"""## **Model Three** -

Using Transfer Learning From VGG Net Pretrained Model

**Build Model**
"""

class VGG16Pretrained(nn.Module):
    def __init__(self, num_classes=3):
        super(VGG16Pretrained, self).__init__()
        self.vgg16 = models.vgg16(pretrained=True)
        #modify classifier (last layer) to fit number of classes
        num_ftrs = self.vgg16.classifier[6].in_features
        self.vgg16.classifier[6] = nn.Linear(num_ftrs, num_classes)

    def forward(self, x):
        x = self.vgg16(x)
        return x

"""**Get Summary**"""

#model summary
model3 = VGG16Pretrained()

#instantiate model summary class
model_summary = ModelSummary(model3)

#display model summary
print(model_summary)

"""**Train Model**"""

#set seed before training
set_seed(seed=36)

#train model three
#initialize model
model3 = VGG16Pretrained()

#set parameters
optimizer = torch.optim.Adam
optimizer_params = {'lr': 0.0001}

#instantiate optimizer
optimizer_instance = optimizer(model3.parameters(), **optimizer_params)

#instantiate trainer
trainer = Trainer(
    model=model3,
    train_loader=train_loader2,
    val_loader=val_loader2,
    criterion=nn.CrossEntropyLoss().to(device),
    optimizer=optimizer_instance,
    device=device,
    num_epochs=num_epochs,
    model_name='model3',
    verbose=True
)

#train model
trainer.train()

#save training history for model 3
history3 = {
    'train_loss_history': trainer.train_loss_history,
    'val_loss_history': trainer.val_loss_history,
    'train_acc_history': trainer.train_acc_history,
    'val_acc_history': trainer.val_acc_history,
}
save_training_history(history3, 'training_history_model3.pkl')

"""**Plot Training Curves**"""

#instantiate TrainCurvePlotter with saved training history
plotter = TrainCurvePlotter('training_history_model3.pkl')

#load training history
plotter.load_training_history()

#plot training curves
plotter.plot()

"""**Make Predictions**"""

#instantiate ModelPredictor
predictor = ModelPredictor(model3, val_loader2, device)

#predict the class labels of all the images val loader
predictions, true_labels = predictor.predict()

#display predictions
print(f"Model Two- Predictions: \n{predictions}")

#print the accuracy of the model on the val dataset
accuracy = (predictions == true_labels).mean()
print(f"\nModel Three - Validation Accuracy: {accuracy * 100:.2f}%")

#get a random sample from val loader
random_batch = random.choice(val_loader2.dataset)

#extract image and label from random sample
image, label = random_batch

#add a batch dimension to image
image = image.unsqueeze(0).to(device)

#make predictions for random image
outputs = model3(image)

#get the predicted class label
predicted_class_label = outputs[0].argmax().item()

#get the class names for the predicted and true labels
predicted_class_name = class_labels[predicted_class_label]
true_class_name = class_labels[label]

#display results
print(f"Predicted class label: {predicted_class_label}")
print(f"Predicted class name: {predicted_class_name}")
print(f"True class label: {label}")
print(f"True class name: {true_class_name}")

#move image to CPU for plotting
image = image.squeeze(0).cpu()

#convert image tensor to numpy array
image = image.permute(1, 2, 0).numpy()  #rearrange dimensions for matplotlib (H, W, C)

#plot the image
plt.figure(figsize=(6, 6))
plt.imshow(image)
plt.title(f"Predicted: {predicted_class_name}\nTrue: {true_class_name}", fontsize=16)
plt.axis('off')
plt.show()

#plot predictions vs. true labels
predictor.plot_predictions()

"""# **Models Evaluation & Performance**

## Model One - Evaluation & Performance
"""

#initiate dict to store model results
model_results = {}

#instantiate ModelEvaluator class
evaluator = ModelEvaluator(model1, test_loader, device)

#get test accuracy
test_accuracy = evaluator.evaluate()

print(f"Model One - Accuracy: {test_accuracy * 100:.2f}%")

#instantiate ModelPredictor
predictor = ModelPredictor(model1, test_loader, device)

#predict the class labels of all images in test loader
predictions, true_labels = predictor.predict()

#instantiate performance metrics
metrics = PerformanceMetrics(true_labels, predictions, class_labels)

#calculate accuracy
accuracy = metrics.calculate_accuracy()
print(f"Accuracy: {accuracy:.2f}%, \n")

#calculate specificity
specificity = metrics.calculate_specificity()
print(f"Specificity: {specificity:.2f}%, \n")

#calculate sensitivity
sensitivity = metrics.calculate_sensitivity()
print(f"Sensitivity: {sensitivity:.2f}%, \n")

#calculate precision
precision = metrics.calculate_precision()
print(f"Precision: {precision:.2f}%, \n")

print("*" * 100)

#display classification report
report = metrics.generate_classification_report()
print(report)

#display heatmap
metrics.plot_heatmap()

#store model 1 metrics
model1_metrics = {
    "Accuracy": accuracy,
    "Specificity": specificity,
    "Sensitivity": sensitivity,
    "Precision": precision,
    "Classification Report": classification_report
}

#add model 1 results to the dictionary
model_results["Model One"] = model1_metrics

"""## Model Two - Evaluation & Performance"""

#instantiate ModelEvaluator class
evaluator = ModelEvaluator(model2, test_loader2, device)

#get test accuracy
test_accuracy = evaluator.evaluate()

print(f"Model One - Accuracy: {test_accuracy * 100:.2f}%")

#instantiate ModelPredictor
predictor = ModelPredictor(model2, test_loader2, device)

#predict the class labels of all images in test loader
predictions, true_labels = predictor.predict()

#instantiate performance metrics
metrics = PerformanceMetrics(true_labels, predictions, class_labels)

#calculate accuracy
accuracy = metrics.calculate_accuracy()
print(f"Accuracy: {accuracy:.2f}%, \n")

#calculate specificity
specificity = metrics.calculate_specificity()
print(f"Specificity: {specificity:.2f}%, \n")

#calculate sensitivity
sensitivity = metrics.calculate_sensitivity()
print(f"Sensitivity: {sensitivity:.2f}%, \n")

#calculate precision
precision = metrics.calculate_precision()
print(f"Precision: {precision:.2f}%, \n")

print("*" * 100)

#display classification report
report = metrics.generate_classification_report()
print(report)

#display heatmap
metrics.plot_heatmap()

#store model 2 metrics
model2_metrics = {
    "Accuracy": accuracy,
    "Specificity": specificity,
    "Sensitivity": sensitivity,
    "Precision": precision,
    "Classification Report": classification_report
}

#add model 2 results to the dictionary
model_results["Model Two"] = model2_metrics

"""## Model Three - Evaluation & Performance"""

#instantiate ModelEvaluator class
evaluator = ModelEvaluator(model3, test_loader2, device)

#get test accuracy
test_accuracy = evaluator.evaluate()

print(f"Model Three - Accuracy: {test_accuracy * 100:.2f}%")

#instantiate ModelPredictor
predictor = ModelPredictor(model3, test_loader2, device)

#predict the class labels of all images in test loader
predictions, true_labels = predictor.predict()

#instantiate performance metrics
metrics = PerformanceMetrics(true_labels, predictions, class_labels)

#calculate accuracy
accuracy = metrics.calculate_accuracy()
print(f"Accuracy: {accuracy:.2f}%, \n")

#calculate specificity
specificity = metrics.calculate_specificity()
print(f"Specificity: {specificity:.2f}%, \n")

#calculate sensitivity
sensitivity = metrics.calculate_sensitivity()
print(f"Sensitivity: {sensitivity:.2f}%, \n")

#calculate precision
precision = metrics.calculate_precision()
print(f"Precision: {precision:.2f}%, \n")

print("*" * 100)

#display classification report
report = metrics.generate_classification_report()
print(report)

#display heatmap
metrics.plot_heatmap()

#store model 3 metrics
model3_metrics = {
    "Accuracy": accuracy,
    "Specificity": specificity,
    "Sensitivity": sensitivity,
    "Precision": precision,
    "Classification Report": classification_report
}

#add model 3 results to the dictionary
model_results["Model Three"] = model3_metrics

"""# **Models Comparison**"""

#initialize model comparison class
model_results = model_results

model_comparison = ModelComparison(model_results)

"""## Accuracy"""

#plot accuracy
model_comparison.plot_accuracy()

"""## Specificity"""

#plot sppecificity
model_comparison.plot_specificity()

"""## Sensitivity"""

#plot sensitivity
model_comparison.plot_sensitivity()

"""## Precision"""

#plot precision
model_comparison.plot_precision()

"""# **References**


1. Dataset:
Borhani, I. "Animal Image Classification Dataset." Kaggle. https://kaggle.com/datasets/borhanitrash/animal-image-classification-dataset/data.

2. Adapted Code:
Amua, U. R. "Brain Tumor Classification." GitHub. https://github.com/sleekyucee/brain-tumor.

3. Some portions of the code were adapted from lecture notes provided by Dr. Atif Riaz in the course Programming and Mathematics for Artificial Intelligence.
"""

